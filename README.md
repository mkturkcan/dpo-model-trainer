# DPO Trainer

This notebook employs Unsloth and Gemma 2 for training a LORA using DPO. [gemma2-9b-it](https://huggingface.co/google/gemma-2-9b-it) is a good base model for finetuning LLMs with a small budget, and the notebook focuses on its use. The notebook also shows how to combine and use datasets in HuggingFace to train your own models efficiently.

## Setup

You need Unsloth, transformers, and (ideally/optionally) flash attention.

## Models

Models trained using the notebook will be released soon.

